% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_summary.R
\name{superSumFun}
\alias{superSumFun}
\title{Custom two-class summary function}
\usage{
superSumFun(data, lev = NULL, model = NULL)
}
\arguments{
\item{data}{a data frame with columns \code{obs} and \code{pred} for the observed and predicted outcomes, 
and columns with predicted probabilities for each outcome class. 
See the \code{classProbs} argument to \code{\link[caret]{trainControl}}.}

\item{lev}{a character vector of factors levels for the response.
First element is passed to \code{\link[caret]{confusionMatrix}}'s \code{positive}.}

\item{model}{a character string for the model name 
(as taken from the \code{method} argument of \code{\link[caret]{train}}.)}

\item{pred}{A vector of numeric data (could be a factor)}

\item{obs}{A vector of numeric data (could be a factor)}
}
\description{
Function used to compute performance metrics when running \code{\link[caret]{train}}.
}
\details{
The following metrics are returned as a named numeric vector:
    \itemize{
        \item{\code{Accuracy}: (TP+TN)/N}
        \item{\code{AccuracyNull}: Prevalence of "positive" class}
        \item{\code{AccuracyPValue}: p-value of \code{Accuracy} compared to \code{AccuracyNull}}
        \item{\code{Balanced Accuracy}: (\code{Sensitivity}+\code{Specificity})/2}
        \item{\code{Precision}: TP/(TP+FP) ('How many instance \emph{labeled positive} are correctly classified?')}
        \item{\code{Recall}: TP/(TP+FN) ('How many of \emph{truly positive} instances are labeled correctly?')}
        \item{\code{Sensitivity}: TP/(TP+FN) = \code{Recall} (true-positive rate)}
        \item{\code{Specificity}: TN/(TN+FP) = 1/\code{Recall} (inverse Recall, true-negative rate)}
        \item{\code{Kappa}: }
        \item{\code{logLoss}: negative log-likelihood of the binomial distribution}
        \item{\code{AUC}: Area under the Receiver Operating Characteristic (ROC) curve}
        \item{\code{PR-AUC}: Area under the Precision-Recall ROC curve}
        \item{\code{F0.5}: F-measure (see Notes) with β = .5 (twice as much weight on Precision as on Recall)}
        \item{\code{F1}: F-measure (see Notes) with β = 1 (Precision and Recall weighted equally)}
        \item{\code{F2}: F-measure (see Notes) with β = 2 (twice as much weight on Recall as on Precision)}
    }
Note: The F-measure is computed as (1+β²) x (Precision x Recall)/(β²xPrecision + Recall)
}
\examples{
\dontrun{
library(dplyr)
dat <- data.frame(
  pred = sample(1:2, 10, replace = T)
  , obs = sample(1:2, 10, replace = T)
) \%>\% 
  mutate(
    `1` = ifelse(pred == 1, sample(seq(.51, .99, length.out = 100), 10), sample(seq(0.01, .49, length.out = 100), 10))
    , `2` = 1-`1`
  ) \%>\% 
  mutate_at(1:2, as.factor)
superSumFun(dat, levels(dat$obs))
} 

}
